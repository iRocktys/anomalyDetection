{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento UEL - Gerando dados para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos treino_final_estratificado_random.csv e teste_final_estratificado_random.csv gerados com sequências aleatórias!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import cycle\n",
    "import random\n",
    "\n",
    "# 1. Carregar os arquivos\n",
    "teste_ataque = pd.read_csv('data/cic_puro/teste_ataque_ordenado.csv', sep=';')\n",
    "teste_normal = pd.read_csv('data/cic_puro/teste_sem_ataque_ordenado.csv', sep=';')\n",
    "treino_ataque = pd.read_csv('data/cic_puro/treino_ataque_ordenado.csv', sep=';')\n",
    "treino_normal = pd.read_csv('data/cic_puro/treino_sem_ataque_ordenado.csv', sep=';')\n",
    "\n",
    "\n",
    "# 2. Concatenar para treino e teste\n",
    "teste_full = pd.concat([teste_normal, teste_ataque], ignore_index=True)\n",
    "treino_full = pd.concat([treino_normal, treino_ataque], ignore_index=True)\n",
    "\n",
    "# 3. Separar normais e ataques\n",
    "def prepare_data(df, max_per_attack=1000, max_normal=5000):\n",
    "    normal = df[df['label'] == 0].sample(frac=1).reset_index(drop=True)  # embaralhar normais\n",
    "    attacks = df[df['label'] == 1].reset_index(drop=True)\n",
    "\n",
    "    # Agora limitar por tipo de ataque\n",
    "    attack_types = {}\n",
    "    for name, group in attacks.groupby('attack_name'):\n",
    "        attack_types[name] = group.sample(n=min(len(group), max_per_attack)).reset_index(drop=True)\n",
    "\n",
    "    # Limitar normais\n",
    "    if max_normal is not None:\n",
    "        normal = normal.sample(n=min(len(normal), max_normal)).reset_index(drop=True)\n",
    "\n",
    "    return normal, attack_types\n",
    "\n",
    "train_normal, train_attacks = prepare_data(treino_full, max_per_attack=1000, max_normal=10000)\n",
    "test_normal, test_attacks = prepare_data(teste_full, max_per_attack=500, max_normal=5000)\n",
    "\n",
    "# 4. Função para criar sequências aleatórias\n",
    "def create_random_sequences(normal_df, attack_dict, min_seq=30, max_seq=150):\n",
    "    final_rows = []\n",
    "    \n",
    "    normal_iter = normal_df.iterrows()\n",
    "    attack_iters = {k: v.iterrows() for k, v in attack_dict.items()}\n",
    "    attack_cycle = cycle(list(attack_iters.keys()))\n",
    "    \n",
    "    normal_remaining = True\n",
    "    attack_remaining = True\n",
    "\n",
    "    while normal_remaining or attack_remaining:\n",
    "        choice = random.choice(['normal', 'attack'])  # Aleatoriamente decidir normal ou ataque primeiro\n",
    "        \n",
    "        if choice == 'normal' and normal_remaining:\n",
    "            seq_len = random.randint(min_seq, max_seq)\n",
    "            for _ in range(seq_len):\n",
    "                try:\n",
    "                    idx, row = next(normal_iter)\n",
    "                    final_rows.append(row)\n",
    "                except StopIteration:\n",
    "                    normal_remaining = False\n",
    "                    break\n",
    "        \n",
    "        elif choice == 'attack' and attack_remaining:\n",
    "            attack_type = next(attack_cycle)\n",
    "            seq_len = random.randint(min_seq, max_seq)\n",
    "            for _ in range(seq_len):\n",
    "                try:\n",
    "                    idx, row = next(attack_iters[attack_type])\n",
    "                    final_rows.append(row)\n",
    "                except StopIteration:\n",
    "                    # Se esgotar ataques desse tipo, remover do ciclo\n",
    "                    del attack_iters[attack_type]\n",
    "                    if attack_iters:\n",
    "                        attack_cycle = cycle(list(attack_iters.keys()))\n",
    "                    else:\n",
    "                        attack_remaining = False\n",
    "                    break\n",
    "        else:\n",
    "            # Se o tipo escolhido acabou, tenta o outro\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(final_rows)\n",
    "\n",
    "# 5. Criar datasets\n",
    "train_final = create_random_sequences(train_normal, train_attacks, min_seq=30, max_seq=120)\n",
    "test_final = create_random_sequences(test_normal, test_attacks, min_seq=30, max_seq=120)\n",
    "\n",
    "# 6. Salvar\n",
    "train_final.to_csv('treino_final_estratificado_random.csv', sep=';', index=False)\n",
    "test_final.to_csv('teste_final_estratificado_random.csv', sep=';', index=False)\n",
    "\n",
    "print('Arquivos treino_final_estratificado_random.csv e teste_final_estratificado_random.csv gerados com sequências aleatórias!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho: 13 Treino: attack_name\n",
      "normal           8074\n",
      "DrDoS_DNS        1000\n",
      "DrDoS_NTP        1000\n",
      "DrDoS_SNMP       1000\n",
      "DrDoS_UDP        1000\n",
      "TFTP             1000\n",
      "UDP-lag           885\n",
      "DrDoS_SSDP        822\n",
      "DrDoS_NetBIOS     726\n",
      "DrDoS_MSSQL       687\n",
      "DrDoS_LDAP        592\n",
      "Syn               237\n",
      "WebDDoS           125\n",
      "Name: count, dtype: int64\n",
      "Tamanho: 8 Teste: attack_name\n",
      "normal     5000\n",
      "LDAP        500\n",
      "MSSQL       500\n",
      "NetBIOS     500\n",
      "Syn         500\n",
      "UDP         500\n",
      "UDPLag      470\n",
      "Portmap     449\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar a quantidade de cada valor na coluna 'attack_name'\n",
    "attack_counts_train = train_final['attack_name'].value_counts()\n",
    "attack_counts_test = test_final['attack_name'].value_counts()\n",
    "\n",
    "# Exibir os resultados\n",
    "print('Tamanho:', len(train_final), 'Treino:', attack_counts_train)\n",
    "print('Total de linhas no conjunto de treino:', len(train_final))\n",
    "\n",
    "print('Tamanho:', len(test_final), 'Teste:', attack_counts_test)\n",
    "print('Total de linhas no conjunto de teste:', len(test_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "from models.LSTM import LSTM\n",
    "from models.Sequence import SequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Configurações gerais\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Parâmetros do dataset e modelo\n",
    "input_size      = 9\n",
    "hidden_size     = 256\n",
    "num_layers      = 3\n",
    "output_size     = 2\n",
    "batch_size      = 128\n",
    "sequence_length = 50\n",
    "column_to_remove= 'attack_name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "Total de amostras no treino: 17099\n",
      "Total de amostras no teste:  8370\n",
      "Train Shape: torch.Size([17099, 50, 9])\n",
      "Test  Shape: torch.Size([8370, 50, 9])\n",
      "Batches treino: 134, teste: 66\n",
      "LSTM(\n",
      "  (lstm1): LSTM(9, 128, num_layers=3, batch_first=True)\n",
      "  (lstm2): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (lstm3): LSTM(256, 128, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Criar os datasets\n",
    "train_dataset = SequenceDataset(\n",
    "    path             = 'data/dataset/treino_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    path             = 'data/dataset/teste_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "\n",
    "print(f\"Total de amostras no treino: {len(train_dataset)}\")\n",
    "print(f\"Total de amostras no teste:  {len(test_dataset)}\")\n",
    "print(\"Train Shape:\", train_dataset.sequences.shape)\n",
    "print(\"Test  Shape:\", test_dataset.sequences.shape)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size)\n",
    "print(f\"Batches treino: {len(train_loader)}, teste: {len(test_loader)}\")\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = LSTM(input_size=input_size,\n",
    "             hidden_size=hidden_size,\n",
    "             num_layers=num_layers,\n",
    "             output_size=output_size).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1/50 — Train Loss: 0.3468 — Val Acc: 0.9004\n",
      "→ Checkpoint salvo: LSTM_0.9004.pth\n",
      "Ep 2/50 — Train Loss: 0.1354 — Val Acc: 0.9041\n",
      "→ Checkpoint salvo: LSTM_0.9041.pth\n",
      "Ep 3/50 — Train Loss: 0.0992 — Val Acc: 0.9016\n",
      "Ep 4/50 — Train Loss: 0.0851 — Val Acc: 0.9097\n",
      "→ Checkpoint salvo: LSTM_0.9097.pth\n",
      "Ep 5/50 — Train Loss: 0.0700 — Val Acc: 0.9075\n",
      "Ep 6/50 — Train Loss: 0.0839 — Val Acc: 0.8986\n",
      "Ep 7/50 — Train Loss: 0.1061 — Val Acc: 0.9097\n",
      "Ep 8/50 — Train Loss: 0.0886 — Val Acc: 0.9220\n",
      "→ Checkpoint salvo: LSTM_0.9220.pth\n",
      "Ep 9/50 — Train Loss: 0.0819 — Val Acc: 0.9139\n",
      "Ep 10/50 — Train Loss: 0.0739 — Val Acc: 0.9211\n",
      "Ep 11/50 — Train Loss: 0.0702 — Val Acc: 0.8742\n",
      "Ep 12/50 — Train Loss: 0.0818 — Val Acc: 0.9234\n",
      "→ Checkpoint salvo: LSTM_0.9234.pth\n",
      "Ep 13/50 — Train Loss: 0.0692 — Val Acc: 0.9223\n",
      "Ep 14/50 — Train Loss: 0.0808 — Val Acc: 0.9211\n",
      "Ep 15/50 — Train Loss: 0.0655 — Val Acc: 0.9234\n",
      "Ep 16/50 — Train Loss: 0.0633 — Val Acc: 0.9182\n",
      "Ep 17/50 — Train Loss: 0.0534 — Val Acc: 0.9287\n",
      "→ Checkpoint salvo: LSTM_0.9287.pth\n",
      "Ep 18/50 — Train Loss: 0.0523 — Val Acc: 0.9303\n",
      "→ Checkpoint salvo: LSTM_0.9303.pth\n",
      "Ep 19/50 — Train Loss: 0.0548 — Val Acc: 0.9086\n",
      "Ep 20/50 — Train Loss: 0.0532 — Val Acc: 0.9294\n",
      "Ep 21/50 — Train Loss: 0.0412 — Val Acc: 0.9148\n",
      "Ep 22/50 — Train Loss: 0.0450 — Val Acc: 0.9425\n",
      "→ Checkpoint salvo: LSTM_0.9425.pth\n",
      "Ep 23/50 — Train Loss: 0.0462 — Val Acc: 0.9350\n",
      "Ep 24/50 — Train Loss: 0.0355 — Val Acc: 0.9470\n",
      "→ Checkpoint salvo: LSTM_0.9470.pth\n",
      "Ep 25/50 — Train Loss: 0.0410 — Val Acc: 0.9293\n",
      "Ep 26/50 — Train Loss: 0.0601 — Val Acc: 0.9096\n",
      "Ep 27/50 — Train Loss: 0.0593 — Val Acc: 0.9153\n",
      "Ep 28/50 — Train Loss: 0.0451 — Val Acc: 0.9171\n",
      "Ep 29/50 — Train Loss: 0.0353 — Val Acc: 0.9180\n",
      "Ep 30/50 — Train Loss: 0.0442 — Val Acc: 0.9019\n",
      "Ep 31/50 — Train Loss: 0.0336 — Val Acc: 0.9170\n",
      "Ep 32/50 — Train Loss: 0.0457 — Val Acc: 0.9292\n",
      "Ep 33/50 — Train Loss: 0.0350 — Val Acc: 0.9167\n",
      "Ep 34/50 — Train Loss: 0.0297 — Val Acc: 0.9201\n",
      "Ep 35/50 — Train Loss: 0.0375 — Val Acc: 0.9183\n",
      "Ep 36/50 — Train Loss: 0.0312 — Val Acc: 0.9195\n",
      "Ep 37/50 — Train Loss: 0.0324 — Val Acc: 0.9205\n",
      "Ep 38/50 — Train Loss: 0.1199 — Val Acc: 0.9116\n",
      "Ep 39/50 — Train Loss: 0.0686 — Val Acc: 0.9124\n",
      "Ep 40/50 — Train Loss: 0.0392 — Val Acc: 0.9141\n",
      "Ep 41/50 — Train Loss: 0.0465 — Val Acc: 0.9085\n",
      "Ep 42/50 — Train Loss: 0.0303 — Val Acc: 0.9129\n",
      "Ep 43/50 — Train Loss: 0.0275 — Val Acc: 0.9131\n",
      "Ep 44/50 — Train Loss: 0.0287 — Val Acc: 0.9176\n",
      "Ep 45/50 — Train Loss: 0.0282 — Val Acc: 0.9186\n",
      "Ep 46/50 — Train Loss: 0.0246 — Val Acc: 0.9103\n",
      "Ep 47/50 — Train Loss: 0.0222 — Val Acc: 0.9134\n",
      "Ep 48/50 — Train Loss: 0.0215 — Val Acc: 0.9205\n",
      "Ep 49/50 — Train Loss: 0.0257 — Val Acc: 0.8867\n",
      "Ep 50/50 — Train Loss: 0.0434 — Val Acc: 0.9136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm1): LSTM(9, 128, num_layers=3, batch_first=True)\n",
       "  (lstm2): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (lstm3): LSTM(256, 128, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina e salva\n",
    "model.train_model(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    device=device,\n",
    "    epochs=50,\n",
    "    lr=1e-3,\n",
    "    save_dir='output/LSTM',\n",
    "    threshold=0.87\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 'output/LSTM/LSTM_0.9470.pth' carregado com sucesso!\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      4965\n",
      "           1       0.93      0.94      0.94      3405\n",
      "\n",
      "    accuracy                           0.95      8370\n",
      "   macro avg       0.94      0.95      0.95      8370\n",
      "weighted avg       0.95      0.95      0.95      8370\n",
      "\n",
      "Accuracy: 0.9469534050179211\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SequenceDataset(\n",
    "    path             = 'data/dataset/teste_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size)\n",
    "\n",
    "# Instanciar o modelo e mover para device\n",
    "model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Carregar o checkpoint salvo \n",
    "checkpoint_path = 'output/LSTM/LSTM_0.9470.pth'\n",
    "state = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "print(f\"Checkpoint '{checkpoint_path}' carregado com sucesso!\")\n",
    "\n",
    "# Avaliar o modelo\n",
    "model.evaluate(test_loader, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "from models.CNN import CNN\n",
    "from models.Sequence import SequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# hiperparâmetros\n",
    "sequence_length = 70\n",
    "column_to_remove = 'attack_name'\n",
    "batch_size      = 64\n",
    "input_channels  = None  \n",
    "input_length    = sequence_length\n",
    "num_classes     = 2\n",
    "epochs          = 20\n",
    "lr              = 1e-3\n",
    "threshold       = 0.87\n",
    "save_dir        = 'output/CNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras no conjunto de treino: 17079\n",
      "Total de amostras no conjunto de teste: 8350\n",
      "Train Dataset Shape: torch.Size([17079, 9, 70])\n",
      "Test Dataset Shape: torch.Size([8350, 9, 70])\n",
      "Total de batches no conjunto de treino: 267\n",
      "Total de batches no conjunto de teste: 131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv1d(9, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc1): Linear(in_features=17920, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = SequenceDataset('data/dataset/treino_final_estratificado_random.csv', sequence_length, column_to_remove, normalize=True, mode='cnn1d')\n",
    "valid_dataset = SequenceDataset('data/dataset/teste_final_estratificado_random.csv', sequence_length, column_to_remove, normalize=True, mode='cnn1d')\n",
    "\n",
    "print(f\"Total de amostras no conjunto de treino: {len(train_dataset)}\")\n",
    "print(f\"Total de amostras no conjunto de teste: {len(valid_dataset)}\")\n",
    "print(\"Train Dataset Shape:\", train_dataset.sequences.shape)\n",
    "print(\"Test Dataset Shape:\", valid_dataset.sequences.shape)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"Total de batches no conjunto de treino: {len(train_loader)}\")\n",
    "print(f\"Total de batches no conjunto de teste: {len(valid_loader)}\")\n",
    "\n",
    "# Modelo\n",
    "input_channels = train_dataset.sequences.shape[1]\n",
    "model = CNN(\n",
    "    input_channels=input_channels,\n",
    "    input_length=sequence_length,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1/20 – Train Loss: 0.1183 – Val Acc: 0.9020\n",
      "→ Checkpoint salvo: CNN_0.9020.pth\n",
      "Ep 2/20 – Train Loss: 0.0532 – Val Acc: 0.9150\n",
      "→ Checkpoint salvo: CNN_0.9150.pth\n",
      "Ep 3/20 – Train Loss: 0.0374 – Val Acc: 0.9071\n",
      "Ep 4/20 – Train Loss: 0.0334 – Val Acc: 0.9205\n",
      "→ Checkpoint salvo: CNN_0.9205.pth\n",
      "Ep 5/20 – Train Loss: 0.0236 – Val Acc: 0.8795\n",
      "Ep 6/20 – Train Loss: 0.0205 – Val Acc: 0.8381\n",
      "Ep 7/20 – Train Loss: 0.0182 – Val Acc: 0.9139\n",
      "Ep 8/20 – Train Loss: 0.0141 – Val Acc: 0.9151\n",
      "Ep 9/20 – Train Loss: 0.0120 – Val Acc: 0.9333\n",
      "→ Checkpoint salvo: CNN_0.9333.pth\n",
      "Ep 10/20 – Train Loss: 0.0077 – Val Acc: 0.9195\n",
      "Ep 11/20 – Train Loss: 0.0159 – Val Acc: 0.9256\n",
      "Ep 12/20 – Train Loss: 0.0068 – Val Acc: 0.8966\n",
      "Ep 13/20 – Train Loss: 0.0082 – Val Acc: 0.8862\n",
      "Ep 14/20 – Train Loss: 0.0057 – Val Acc: 0.9013\n",
      "Ep 15/20 – Train Loss: 0.0037 – Val Acc: 0.9242\n",
      "Ep 16/20 – Train Loss: 0.0074 – Val Acc: 0.9279\n",
      "Ep 17/20 – Train Loss: 0.0062 – Val Acc: 0.9170\n",
      "Ep 18/20 – Train Loss: 0.0018 – Val Acc: 0.9055\n",
      "Ep 19/20 – Train Loss: 0.0053 – Val Acc: 0.9054\n",
      "Ep 20/20 – Train Loss: 0.0071 – Val Acc: 0.8457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv1d(9, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc1): Linear(in_features=17920, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinar\n",
    "model.train_model(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    lr=lr,\n",
    "    save_dir=save_dir,\n",
    "    threshold=threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 'output/CNN/CNN_0.9333.pth' carregado com sucesso!\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      4965\n",
      "           1       0.93      0.90      0.92      3385\n",
      "\n",
      "    accuracy                           0.93      8350\n",
      "   macro avg       0.93      0.93      0.93      8350\n",
      "weighted avg       0.93      0.93      0.93      8350\n",
      "\n",
      "Accuracy: 0.9332934131736527\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SequenceDataset(\n",
    "    path             = 'data/dataset/teste_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'cnn1d'\n",
    ")\n",
    "\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size)\n",
    "\n",
    "# Modelo\n",
    "input_channels = test_dataset.sequences.shape[1]\n",
    "model = CNN(\n",
    "    input_channels=input_channels,\n",
    "    input_length=sequence_length,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "\n",
    "# Carregar o checkpoint salvo \n",
    "checkpoint_path = 'output/CNN/CNN_0.9333.pth'\n",
    "state = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "print(f\"Checkpoint '{checkpoint_path}' carregado com sucesso!\")\n",
    "\n",
    "# Avaliar o modelo\n",
    "model.evaluate(test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models.Sequence import SequenceDataset\n",
    "from models.Hybrid import ModelHybridAttnSVM\n",
    "\n",
    "# Fix seed e escolher device\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Hiperparâmetros\n",
    "sequence_length = 70\n",
    "column_to_remove = 'attack_name'\n",
    "batch_size      = 64\n",
    "lstm_hidden     = 64\n",
    "lstm_layers     = 2\n",
    "num_classes     = 2\n",
    "pca_components  = 30\n",
    "svm_C           = 1.0\n",
    "epochs          = 50\n",
    "lr              = 1e-3\n",
    "threshold       = 0.87\n",
    "save_dir        = 'output/Hybrid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras no conjunto de treino: 17079\n",
      "Total de amostras no conjunto de teste:  8350\n",
      "Train Dataset Shape: torch.Size([17079, 70, 9])\n",
      "Test  Dataset Shape: torch.Size([8350, 70, 9])\n",
      "Total de batches no treino: 267\n",
      "Total de batches no teste:  131\n",
      "ModelHybridAttnSVM(\n",
      "  (conv1): Conv1d(9, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu): ReLU()\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (lstm): LSTM(128, 64, num_layers=2, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Criar os datasets\n",
    "train_dataset = SequenceDataset(\n",
    "    path             = 'data/dataset/treino_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "valid_loader = SequenceDataset(\n",
    "    path             = 'data/dataset/teste_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "\n",
    "print(f\"Total de amostras no conjunto de treino: {len(train_dataset)}\")\n",
    "print(f\"Total de amostras no conjunto de teste:  {len(valid_loader)}\")\n",
    "print(\"Train Dataset Shape:\", train_dataset.sequences.shape)\n",
    "print(\"Test  Dataset Shape:\", valid_loader.sequences.shape)\n",
    "\n",
    "# Criar os DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader  = DataLoader(valid_loader,  batch_size=batch_size)\n",
    "\n",
    "print(f\"Total de batches no treino: {len(train_loader)}\")\n",
    "print(f\"Total de batches no teste:  {len(test_loader)}\")\n",
    "\n",
    "# Instanciar o modelo\n",
    "n_features = train_dataset.sequences.shape[2]\n",
    "model = ModelHybridAttnSVM(\n",
    "    seq_len         = sequence_length,\n",
    "    n_features      = n_features,\n",
    "    lstm_hidden     = lstm_hidden,\n",
    "    lstm_layers     = lstm_layers,\n",
    "    num_classes     = num_classes,\n",
    "    pca_components  = pca_components,\n",
    "    svm_C           = svm_C\n",
    ").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1/50 – Train Loss: 0.2138 – Val Acc: 0.8995\n",
      "→ Checkpoint salvo: Hybrid_0.90.pth\n",
      "Ep 2/50 – Train Loss: 0.1052 – Val Acc: 0.9468\n",
      "→ Checkpoint salvo: Hybrid_0.95.pth\n",
      "Ep 3/50 – Train Loss: 0.0923 – Val Acc: 0.9504\n",
      "→ Checkpoint salvo: Hybrid_0.95.pth\n",
      "Ep 4/50 – Train Loss: 0.0823 – Val Acc: 0.9429\n",
      "Ep 5/50 – Train Loss: 0.0738 – Val Acc: 0.9522\n",
      "→ Checkpoint salvo: Hybrid_0.95.pth\n",
      "Ep 6/50 – Train Loss: 0.0706 – Val Acc: 0.9559\n",
      "→ Checkpoint salvo: Hybrid_0.96.pth\n",
      "Ep 7/50 – Train Loss: 0.0663 – Val Acc: 0.9593\n",
      "→ Checkpoint salvo: Hybrid_0.96.pth\n",
      "Ep 8/50 – Train Loss: 0.0557 – Val Acc: 0.9577\n",
      "Ep 9/50 – Train Loss: 0.0528 – Val Acc: 0.9537\n",
      "Ep 10/50 – Train Loss: 0.0497 – Val Acc: 0.9505\n",
      "Ep 11/50 – Train Loss: 0.0476 – Val Acc: 0.9532\n",
      "Ep 12/50 – Train Loss: 0.0447 – Val Acc: 0.9505\n",
      "Ep 13/50 – Train Loss: 0.0402 – Val Acc: 0.9505\n",
      "Ep 14/50 – Train Loss: 0.0375 – Val Acc: 0.9538\n",
      "Ep 15/50 – Train Loss: 0.0375 – Val Acc: 0.9513\n",
      "Ep 16/50 – Train Loss: 0.0344 – Val Acc: 0.9416\n",
      "Ep 17/50 – Train Loss: 0.0299 – Val Acc: 0.9431\n",
      "Ep 18/50 – Train Loss: 0.0305 – Val Acc: 0.9447\n",
      "Ep 19/50 – Train Loss: 0.0257 – Val Acc: 0.9541\n",
      "Ep 20/50 – Train Loss: 0.0269 – Val Acc: 0.9377\n",
      "Ep 21/50 – Train Loss: 0.0264 – Val Acc: 0.9551\n",
      "Ep 22/50 – Train Loss: 0.0216 – Val Acc: 0.9456\n",
      "Ep 23/50 – Train Loss: 0.0216 – Val Acc: 0.9432\n",
      "Ep 24/50 – Train Loss: 0.0221 – Val Acc: 0.9420\n",
      "Ep 25/50 – Train Loss: 0.0189 – Val Acc: 0.9459\n",
      "Ep 26/50 – Train Loss: 0.0185 – Val Acc: 0.9422\n",
      "Ep 27/50 – Train Loss: 0.0185 – Val Acc: 0.9414\n",
      "Ep 28/50 – Train Loss: 0.0167 – Val Acc: 0.9277\n",
      "Ep 29/50 – Train Loss: 0.0147 – Val Acc: 0.9489\n",
      "Ep 30/50 – Train Loss: 0.0130 – Val Acc: 0.9478\n",
      "Ep 31/50 – Train Loss: 0.0142 – Val Acc: 0.9449\n",
      "Ep 32/50 – Train Loss: 0.0140 – Val Acc: 0.9399\n",
      "Ep 33/50 – Train Loss: 0.0123 – Val Acc: 0.9411\n",
      "Ep 34/50 – Train Loss: 0.0179 – Val Acc: 0.9509\n",
      "Ep 35/50 – Train Loss: 0.0117 – Val Acc: 0.9417\n",
      "Ep 36/50 – Train Loss: 0.0091 – Val Acc: 0.9455\n",
      "Ep 37/50 – Train Loss: 0.0118 – Val Acc: 0.9543\n",
      "Ep 38/50 – Train Loss: 0.0099 – Val Acc: 0.9418\n",
      "Ep 39/50 – Train Loss: 0.0121 – Val Acc: 0.9392\n",
      "Ep 40/50 – Train Loss: 0.0111 – Val Acc: 0.9444\n",
      "Ep 41/50 – Train Loss: 0.0068 – Val Acc: 0.9337\n",
      "Ep 42/50 – Train Loss: 0.0101 – Val Acc: 0.9448\n",
      "Ep 43/50 – Train Loss: 0.0094 – Val Acc: 0.9431\n",
      "Ep 44/50 – Train Loss: 0.0095 – Val Acc: 0.9325\n",
      "Ep 45/50 – Train Loss: 0.0143 – Val Acc: 0.9358\n",
      "Ep 46/50 – Train Loss: 0.0068 – Val Acc: 0.9346\n",
      "Ep 47/50 – Train Loss: 0.0072 – Val Acc: 0.9398\n",
      "Ep 48/50 – Train Loss: 0.0046 – Val Acc: 0.9305\n",
      "Ep 49/50 – Train Loss: 0.0078 – Val Acc: 0.9467\n",
      "Ep 50/50 – Train Loss: 0.0084 – Val Acc: 0.9278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelHybridAttnSVM(\n",
       "  (conv1): Conv1d(9, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (relu): ReLU()\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (lstm): LSTM(128, 64, num_layers=2, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento\n",
    "model.train_model(\n",
    "    train_loader  = train_loader,\n",
    "    valid_loader  = valid_loader,\n",
    "    device        = device,\n",
    "    epochs        = epochs,\n",
    "    lr            = lr,\n",
    "    save_dir      = save_dir,\n",
    "    threshold     = threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(probability=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Treinar PCA + SVM sobre as features extraídas\n",
    "model.train_svm(\n",
    "    train_loader = valid_loader,\n",
    "    device       = device,\n",
    "    pca_path     = f\"{save_dir}/pca.joblib\",\n",
    "    svm_path     = f\"{save_dir}/hybrid_svm.joblib\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras de teste: 8350\n",
      "Test shape: torch.Size([8350, 70, 9])\n",
      "Checkpoint 'output/Hybrid/Hybrid_0.90.pth' carregado com sucesso!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      4965\n",
      "           1       0.84      0.95      0.90      3385\n",
      "\n",
      "    accuracy                           0.91      8350\n",
      "   macro avg       0.90      0.92      0.91      8350\n",
      "weighted avg       0.92      0.91      0.91      8350\n",
      "\n",
      "Accuracy: 0.9094610778443114\n"
     ]
    }
   ],
   "source": [
    "# Dataset e DataLoader para teste\n",
    "test_ds = SequenceDataset(\n",
    "    path             = 'data/dataset/teste_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "print(f\"Total de amostras de teste: {len(test_ds)}\")\n",
    "print(\"Test shape:\", test_ds.sequences.shape)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Instanciar a classe Hybrid com os mesmos hiperparâmetros de treino\n",
    "n_features = test_ds.sequences.shape[2]  # dimensão de features por timestep\n",
    "model = ModelHybridAttnSVM(\n",
    "    seq_len        = sequence_length,\n",
    "    n_features     = n_features,\n",
    "    lstm_hidden    = lstm_hidden,\n",
    "    lstm_layers    = lstm_layers,\n",
    "    num_classes    = num_classes,\n",
    "    pca_components = 30,\n",
    "    svm_C          = 1.0\n",
    ").to(device)\n",
    "\n",
    "# Carregar checkpoint CNN-LSTM salvo \n",
    "checkpoint_path = 'output/Hybrid/Hybrid_0.90.pth'\n",
    "state = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "print(f\"Checkpoint '{checkpoint_path}' carregado com sucesso!\")\n",
    "\n",
    "# Avaliar pipeline completo (CNN→LSTM→PCA→SVM)\n",
    "model.evaluate(\n",
    "    loader    = test_loader,\n",
    "    device    = device,\n",
    "    pca_path  = 'output/Hybrid/pca.joblib',\n",
    "    svm_path  = 'output/Hybrid/hybrid_svm.joblib'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
