{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento UEL - Gerando dados para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos gerados:\n",
      " • treino_final_estratificado_random.csv\n",
      " • validacao_final_estratificado_random.csv\n",
      " • teste_final_estratificado_random.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import cycle\n",
    "import random\n",
    "\n",
    "# 1. Carregar os arquivos originais\n",
    "teste_ataque      = pd.read_csv('data/cic_puro/teste_ataque_ordenado.csv',     sep=';')\n",
    "teste_normal      = pd.read_csv('data/cic_puro/teste_sem_ataque_ordenado.csv', sep=';')\n",
    "treino_ataque     = pd.read_csv('data/cic_puro/treino_ataque_ordenado.csv',    sep=';')\n",
    "treino_normal     = pd.read_csv('data/cic_puro/treino_sem_ataque_ordenado.csv',sep=';')\n",
    "validacao_ataque  = pd.read_csv('data/cic_puro/treino_ataque_ordenado.csv',    sep=';')  # igual ao treino\n",
    "validacao_normal  = pd.read_csv('data/cic_puro/treino_sem_ataque_ordenado.csv',sep=';')  # igual ao treino\n",
    "\n",
    "# 2. Concatenar para os três conjuntos\n",
    "teste_full      = pd.concat([teste_normal,      teste_ataque],     ignore_index=True)\n",
    "treino_full     = pd.concat([treino_normal,     treino_ataque],    ignore_index=True)\n",
    "validacao_full  = pd.concat([validacao_normal,  validacao_ataque], ignore_index=True)\n",
    "\n",
    "# 3. Função para separar normais e ataques, limitando quantidades\n",
    "def prepare_data(df, max_per_attack=1000, max_normal=None):\n",
    "    normal  = df[df['label']==0].sample(frac=1).reset_index(drop=True)\n",
    "    attacks = df[df['label']==1].reset_index(drop=True)\n",
    "\n",
    "    # limita por tipo de ataque\n",
    "    attack_dict = {\n",
    "        name: grp.sample(n=min(len(grp), max_per_attack)).reset_index(drop=True)\n",
    "        for name, grp in attacks.groupby('attack_name')\n",
    "    }\n",
    "\n",
    "    # limita normais, se desejado\n",
    "    if max_normal is not None:\n",
    "        normal = normal.sample(n=min(len(normal), max_normal)).reset_index(drop=True)\n",
    "\n",
    "    return normal, attack_dict\n",
    "\n",
    "# 3a. Preparar dados para treino\n",
    "train_normal,   train_attacks   = prepare_data(treino_full,    max_per_attack=1000, max_normal=10000)\n",
    "# 3b. Preparar dados para validação (vem de validacao_full)\n",
    "valid_normal,   valid_attacks   = prepare_data(validacao_full, max_per_attack=500,  max_normal=5000)\n",
    "# 3c. Preparar dados para teste (baseado em treino_full, mesma forma do treino)\n",
    "test_normal,    test_attacks    = prepare_data(treino_full,    max_per_attack=1000, max_normal=10000)\n",
    "\n",
    "# 4. Função para gerar sequências aleatórias\n",
    "def create_random_sequences(normal_df, attack_dict, min_seq=30, max_seq=120):\n",
    "    rows = []\n",
    "    norm_iter = normal_df.iterrows()\n",
    "    atk_iters = {k: v.iterrows() for k, v in attack_dict.items()}\n",
    "    atk_cycle = cycle(list(atk_iters.keys()))\n",
    "    norm_rem, atk_rem = True, True\n",
    "\n",
    "    while norm_rem or atk_rem:\n",
    "        choice = random.choice(['normal','attack'])\n",
    "        if choice=='normal' and norm_rem:\n",
    "            L = random.randint(min_seq, max_seq)\n",
    "            for _ in range(L):\n",
    "                try:\n",
    "                    _, row = next(norm_iter)\n",
    "                    rows.append(row)\n",
    "                except StopIteration:\n",
    "                    norm_rem=False\n",
    "                    break\n",
    "        elif choice=='attack' and atk_rem:\n",
    "            atk = next(atk_cycle)\n",
    "            L   = random.randint(min_seq, max_seq)\n",
    "            for _ in range(L):\n",
    "                try:\n",
    "                    _, row = next(atk_iters[atk])\n",
    "                    rows.append(row)\n",
    "                except StopIteration:\n",
    "                    del atk_iters[atk]\n",
    "                    if atk_iters:\n",
    "                        atk_cycle = cycle(atk_iters.keys())\n",
    "                    else:\n",
    "                        atk_rem = False\n",
    "                    break\n",
    "        else:\n",
    "            # tipo esgotado, tenta o outro\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# 5. Gerar os três conjuntos de saída\n",
    "train_final = create_random_sequences(train_normal, train_attacks)\n",
    "valid_final = create_random_sequences(valid_normal, valid_attacks)\n",
    "test_final  = create_random_sequences(test_normal,  test_attacks)\n",
    "\n",
    "# 6. Salvar cada CSV com o nome correto\n",
    "train_final.to_csv('treino_final_estratificado_random.csv',      sep=';', index=False)\n",
    "valid_final.to_csv('validacao_final_estratificado_random.csv',  sep=';', index=False)\n",
    "test_final.to_csv( 'teste_final_estratificado_random.csv',      sep=';', index=False)\n",
    "\n",
    "print('Arquivos gerados:')\n",
    "print(' • treino_final_estratificado_random.csv')\n",
    "print(' • validacao_final_estratificado_random.csv')\n",
    "print(' • teste_final_estratificado_random.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho: 17148 Treino: attack_name\n",
      "normal           8074\n",
      "DrDoS_DNS        1000\n",
      "DrDoS_NTP        1000\n",
      "DrDoS_SNMP       1000\n",
      "DrDoS_UDP        1000\n",
      "TFTP             1000\n",
      "UDP-lag           885\n",
      "DrDoS_SSDP        822\n",
      "DrDoS_NetBIOS     726\n",
      "DrDoS_MSSQL       687\n",
      "DrDoS_LDAP        592\n",
      "Syn               237\n",
      "WebDDoS           125\n",
      "Name: count, dtype: int64\n",
      "Total de linhas no conjunto de treino: 17148\n",
      "Tamanho: 17148 Teste: attack_name\n",
      "normal           8074\n",
      "DrDoS_DNS        1000\n",
      "DrDoS_NTP        1000\n",
      "DrDoS_SNMP       1000\n",
      "DrDoS_UDP        1000\n",
      "TFTP             1000\n",
      "UDP-lag           885\n",
      "DrDoS_SSDP        822\n",
      "DrDoS_NetBIOS     726\n",
      "DrDoS_MSSQL       687\n",
      "DrDoS_LDAP        592\n",
      "Syn               237\n",
      "WebDDoS           125\n",
      "Name: count, dtype: int64\n",
      "Total de linhas no conjunto de teste: 17148\n",
      "Tamanho: 10362 Validação: attack_name\n",
      "normal           5000\n",
      "DrDoS_DNS         500\n",
      "DrDoS_LDAP        500\n",
      "DrDoS_MSSQL       500\n",
      "DrDoS_NTP         500\n",
      "DrDoS_NetBIOS     500\n",
      "DrDoS_SNMP        500\n",
      "DrDoS_SSDP        500\n",
      "DrDoS_UDP         500\n",
      "TFTP              500\n",
      "UDP-lag           500\n",
      "Syn               237\n",
      "WebDDoS           125\n",
      "Name: count, dtype: int64\n",
      "Total de linhas no conjunto de validação: 10362\n"
     ]
    }
   ],
   "source": [
    "# Contar a quantidade de cada valor na coluna 'attack_name'\n",
    "attack_counts_train = train_final['attack_name'].value_counts()\n",
    "attack_counts_test = test_final['attack_name'].value_counts()\n",
    "attack_counts_valid = valid_final['attack_name'].value_counts()\n",
    "\n",
    "# Exibir os resultados\n",
    "print('Tamanho:', len(train_final), 'Treino:', attack_counts_train)\n",
    "print('Total de linhas no conjunto de treino:', len(train_final))\n",
    "\n",
    "print('Tamanho:', len(test_final), 'Teste:', attack_counts_test)\n",
    "print('Total de linhas no conjunto de teste:', len(test_final))\n",
    "\n",
    "print('Tamanho:', len(valid_final), 'Validação:', attack_counts_valid)\n",
    "print('Total de linhas no conjunto de validação:', len(valid_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "from models.LSTM import LSTM\n",
    "from models.Sequence import SequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Configurações gerais\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Parâmetros do dataset e modelo\n",
    "input_size      = 9\n",
    "hidden_size     = 256\n",
    "num_layers      = 3\n",
    "output_size     = 2\n",
    "batch_size      = 128\n",
    "sequence_length = 50\n",
    "column_to_remove= 'attack_name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras no treino: 17099\n",
      "Total de amostras na validação:  10313\n",
      "Train Shape: torch.Size([17099, 50, 9])\n",
      "Valid  Shape: torch.Size([10313, 50, 9])\n",
      "Batches treino: 134, teste: 81\n",
      "LSTM(\n",
      "  (lstm1): LSTM(9, 128, num_layers=3, batch_first=True)\n",
      "  (lstm2): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (lstm3): LSTM(256, 128, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Criar os datasets\n",
    "train_dataset = SequenceDataset(\n",
    "    path             = 'data/dataset/treino_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "valid_dataset = SequenceDataset(\n",
    "    path             = 'data/dataset/validacao_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "\n",
    "print(f\"Total de amostras no treino: {len(train_dataset)}\")\n",
    "print(f\"Total de amostras na validação:  {len(valid_dataset)}\")\n",
    "print(\"Train Shape:\", train_dataset.sequences.shape)\n",
    "print(\"Valid  Shape:\", valid_dataset.sequences.shape)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader  = DataLoader(valid_dataset,  batch_size=batch_size)\n",
    "print(f\"Batches treino: {len(train_loader)}, teste: {len(valid_loader)}\")\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = LSTM(input_size=input_size,\n",
    "             hidden_size=hidden_size,\n",
    "             num_layers=num_layers,\n",
    "             output_size=output_size).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 – Train Loss: 0.3492  Val Loss: 0.1858  Val Acc: 0.9431  Val F1: 0.9431\n",
      "→ Novo melhor modelo salvo em 'output/LSTM\\LSTM_best_model.pth'\n",
      "Epoch 2/50 – Train Loss: 0.1674  Val Loss: 0.1101  Val Acc: 0.9674  Val F1: 0.9674\n",
      "→ Novo melhor modelo salvo em 'output/LSTM\\LSTM_best_model.pth'\n",
      "Epoch 3/50 – Train Loss: 0.1129  Val Loss: 0.1208  Val Acc: 0.9647  Val F1: 0.9647\n",
      "Epoch 4/50 – Train Loss: 0.0979  Val Loss: 0.1261  Val Acc: 0.9636  Val F1: 0.9637\n",
      "Epoch 5/50 – Train Loss: 0.0943  Val Loss: 0.0995  Val Acc: 0.9679  Val F1: 0.9679\n",
      "→ Novo melhor modelo salvo em 'output/LSTM\\LSTM_best_model.pth'\n",
      "Epoch 6/50 – Train Loss: 0.1169  Val Loss: 0.0999  Val Acc: 0.9692  Val F1: 0.9692\n",
      "→ Novo melhor modelo salvo em 'output/LSTM\\LSTM_best_model.pth'\n",
      "Epoch 7/50 – Train Loss: 0.0857  Val Loss: 0.1034  Val Acc: 0.9699  Val F1: 0.9699\n",
      "→ Novo melhor modelo salvo em 'output/LSTM\\LSTM_best_model.pth'\n",
      "Epoch 8/50 – Train Loss: 0.0821  Val Loss: 0.1186  Val Acc: 0.9631  Val F1: 0.9630\n",
      "Epoch 9/50 – Train Loss: 0.0670  Val Loss: 0.1107  Val Acc: 0.9669  Val F1: 0.9669\n",
      "Epoch 10/50 – Train Loss: 0.0611  Val Loss: 0.1596  Val Acc: 0.9545  Val F1: 0.9545\n",
      "Epoch 11/50 – Train Loss: 0.0574  Val Loss: 0.1154  Val Acc: 0.9664  Val F1: 0.9663\n",
      "Epoch 12/50 – Train Loss: 0.0458  Val Loss: 0.1160  Val Acc: 0.9663  Val F1: 0.9662\n",
      "Early stopping após 12 épocas sem melhora.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm1): LSTM(9, 128, num_layers=3, batch_first=True)\n",
       "  (lstm2): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (lstm3): LSTM(256, 128, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina e salva\n",
    "model.train_model(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device=device,\n",
    "    epochs=50,\n",
    "    lr=1e-3,\n",
    "    save_dir='output/LSTM',\n",
    "    threshold=0.90\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 'output/LSTM/LSTM_best_model.pth' carregado com sucesso!\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9703    0.9611    0.9657      8025\n",
      "           1     0.9659    0.9740    0.9699      9074\n",
      "\n",
      "    accuracy                         0.9680     17099\n",
      "   macro avg     0.9681    0.9676    0.9678     17099\n",
      "weighted avg     0.9680    0.9680    0.9679     17099\n",
      "\n",
      "Acurácia:  0.9680\n",
      "Precisão:  0.9659\n",
      "Recall:    0.9740\n",
      "F1-Score:  0.9699\n",
      "AUC:       0.9907\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SequenceDataset(\n",
    "    path             = 'data/dataset/teste_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size)\n",
    "\n",
    "# Instanciar o modelo e mover para device\n",
    "model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Carregar o checkpoint salvo \n",
    "checkpoint_path = 'output/LSTM/LSTM_best_model.pth'\n",
    "state = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "print(f\"Checkpoint '{checkpoint_path}' carregado com sucesso!\")\n",
    "\n",
    "# Avaliar o modelo\n",
    "model.evaluate(test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "from models.CNN import CNN\n",
    "from models.Sequence import SequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# hiperparâmetros\n",
    "sequence_length = 70\n",
    "column_to_remove = 'attack_name'\n",
    "batch_size      = 64\n",
    "input_channels  = None  \n",
    "input_length    = sequence_length\n",
    "num_classes     = 2\n",
    "epochs          = 20\n",
    "lr              = 1e-3\n",
    "threshold       = 0.87\n",
    "save_dir        = 'output/CNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras no conjunto de treino: 17079\n",
      "Total de amostras no conjunto de validação: 10293\n",
      "Train Dataset Shape: torch.Size([17079, 9, 70])\n",
      "Valid Dataset Shape: torch.Size([10293, 9, 70])\n",
      "Total de batches no conjunto de treino: 267\n",
      "Total de batches no conjunto de validação: 161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv1d(9, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = SequenceDataset('data/dataset/treino_final_estratificado_random.csv', sequence_length, column_to_remove, normalize=True, mode='cnn1d')\n",
    "valid_dataset = SequenceDataset('data/dataset/validacao_final_estratificado_random.csv', sequence_length, column_to_remove, normalize=True, mode='cnn1d')\n",
    "\n",
    "print(f\"Total de amostras no conjunto de treino: {len(train_dataset)}\")\n",
    "print(f\"Total de amostras no conjunto de validação: {len(valid_dataset)}\")\n",
    "print(\"Train Dataset Shape:\", train_dataset.sequences.shape)\n",
    "print(\"Valid Dataset Shape:\", valid_dataset.sequences.shape)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"Total de batches no conjunto de treino: {len(train_loader)}\")\n",
    "print(f\"Total de batches no conjunto de validação: {len(valid_loader)}\")\n",
    "\n",
    "# Modelo\n",
    "input_channels = train_dataset.sequences.shape[1]\n",
    "model = CNN(\n",
    "    input_channels=input_channels,\n",
    "    input_length=sequence_length,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 – Train Loss: 0.2767  Val Loss:   0.1427  Val Acc:    0.9527\n",
      "→ Novo melhor modelo salvo em 'output/CNN\\CNN_best_model.pth'\n",
      "Epoch 2/20 – Train Loss: 0.1326  Val Loss:   0.1177  Val Acc:    0.9584\n",
      "→ Novo melhor modelo salvo em 'output/CNN\\CNN_best_model.pth'\n",
      "Epoch 3/20 – Train Loss: 0.1110  Val Loss:   0.0896  Val Acc:    0.9776\n",
      "→ Novo melhor modelo salvo em 'output/CNN\\CNN_best_model.pth'\n",
      "Epoch 4/20 – Train Loss: 0.0915  Val Loss:   0.0740  Val Acc:    0.9779\n",
      "→ Novo melhor modelo salvo em 'output/CNN\\CNN_best_model.pth'\n",
      "Epoch 5/20 – Train Loss: 0.0857  Val Loss:   0.0943  Val Acc:    0.9724\n",
      "Epoch 6/20 – Train Loss: 0.0748  Val Loss:   0.0712  Val Acc:    0.9752\n",
      "→ Novo melhor modelo salvo em 'output/CNN\\CNN_best_model.pth'\n",
      "Epoch 7/20 – Train Loss: 0.0682  Val Loss:   0.1097  Val Acc:    0.9701\n",
      "Epoch 8/20 – Train Loss: 0.0613  Val Loss:   0.0749  Val Acc:    0.9728\n",
      "Epoch 9/20 – Train Loss: 0.0542  Val Loss:   0.0825  Val Acc:    0.9744\n",
      "Epoch 10/20 – Train Loss: 0.0446  Val Loss:   0.0788  Val Acc:    0.9723\n",
      "Epoch 11/20 – Train Loss: 0.0411  Val Loss:   0.0855  Val Acc:    0.9740\n",
      "Epoch 12/20 – Train Loss: 0.0364  Val Loss:   0.0885  Val Acc:    0.9698\n",
      "Epoch 13/20 – Train Loss: 0.0332  Val Loss:   0.0996  Val Acc:    0.9654\n",
      "Epoch 14/20 – Train Loss: 0.0322  Val Loss:   0.0913  Val Acc:    0.9736\n",
      "Epoch 15/20 – Train Loss: 0.0284  Val Loss:   0.0845  Val Acc:    0.9748\n",
      "Epoch 16/20 – Train Loss: 0.0258  Val Loss:   0.0933  Val Acc:    0.9727\n",
      "Epoch 17/20 – Train Loss: 0.0254  Val Loss:   0.0907  Val Acc:    0.9702\n",
      "Epoch 18/20 – Train Loss: 0.0243  Val Loss:   0.1002  Val Acc:    0.9715\n",
      "Epoch 19/20 – Train Loss: 0.0224  Val Loss:   0.0945  Val Acc:    0.9711\n",
      "Epoch 20/20 – Train Loss: 0.0223  Val Loss:   0.0967  Val Acc:    0.9728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv1d(9, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinar\n",
    "model.train_model(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    lr=lr,\n",
    "    save_dir=save_dir,\n",
    "    threshold=threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 'output/CNN/CNN_best_model.pth' carregado com sucesso!\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9613    0.9709    0.9661      8005\n",
      "           1     0.9741    0.9655    0.9698      9074\n",
      "\n",
      "    accuracy                         0.9680     17079\n",
      "   macro avg     0.9677    0.9682    0.9679     17079\n",
      "weighted avg     0.9681    0.9680    0.9680     17079\n",
      "\n",
      "Acurácia:  0.9680\n",
      "Precisão:  0.9741\n",
      "Recall:    0.9655\n",
      "F1-Score:  0.9698\n",
      "AUC:       0.9915\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SequenceDataset(\n",
    "    path             = 'data/dataset/teste_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'cnn1d'\n",
    ")\n",
    "\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size)\n",
    "\n",
    "# Modelo\n",
    "input_channels = test_dataset.sequences.shape[1]\n",
    "model = CNN(\n",
    "    input_channels=input_channels,\n",
    "    input_length=sequence_length,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "\n",
    "# Carregar o checkpoint salvo \n",
    "checkpoint_path = 'output/CNN/CNN_best_model.pth'\n",
    "state = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "print(f\"Checkpoint '{checkpoint_path}' carregado com sucesso!\")\n",
    "\n",
    "# Avaliar o modelo\n",
    "model.evaluate(test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 'output/CNN/CNN_best_model.pth' carregado com sucesso!\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      8005\n",
      "           1       0.97      0.97      0.97      9074\n",
      "\n",
      "    accuracy                           0.97     17079\n",
      "   macro avg       0.97      0.97      0.97     17079\n",
      "weighted avg       0.97      0.97      0.97     17079\n",
      "\n",
      "Accuracy: 0.9689677381579718\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from models.Sequence import SequenceDataset\n",
    "from models.CNN import CNN  # ajuste se o caminho for diferente\n",
    "import torch\n",
    "\n",
    "# Dataset\n",
    "test_dataset = SequenceDataset(\n",
    "    path             = 'data/dataset/teste_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'cnn1d'\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Modelo\n",
    "input_channels = test_dataset.sequences.shape[1]\n",
    "model = CNN(\n",
    "    input_channels=input_channels,\n",
    "    input_length=sequence_length,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "\n",
    "# Carregar o checkpoint\n",
    "checkpoint_path = 'output/CNN/CNN_best_model.pth'\n",
    "state = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "print(f\"Checkpoint '{checkpoint_path}' carregado com sucesso!\")\n",
    "\n",
    "# Avaliar o modelo e gerar gráficos\n",
    "model.evaluate(test_loader, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models.Sequence import SequenceDataset\n",
    "from models.Hybrid import ModelHybridAttnSVM\n",
    "\n",
    "# Fix seed e escolher device\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Hiperparâmetros\n",
    "sequence_length = 50\n",
    "column_to_remove = 'attack_name'\n",
    "batch_size      = 64\n",
    "lstm_hidden     = 128\n",
    "lstm_layers     = 4\n",
    "num_classes     = 2\n",
    "pca_components  = 30\n",
    "svm_C           = 1.0\n",
    "epochs          = 100\n",
    "lr              = 1e-4\n",
    "threshold       = 0.95\n",
    "save_dir        = 'output/Hybrid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras no conjunto de treino: 17099\n",
      "Total de amostras no conjunto de validação:  10313\n",
      "Train Dataset Shape: torch.Size([17099, 50, 9])\n",
      "valid Dataset Shape: torch.Size([10313, 50, 9])\n",
      "Total de batches no treino: 268\n",
      "Total de batches no validação:  162\n",
      "ModelHybridAttnSVM(\n",
      "  (conv1): Conv1d(9, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu): ReLU()\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (lstm1): LSTM(128, 64, num_layers=3, batch_first=True)\n",
      "  (lstm2): LSTM(64, 128, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (lstm3): LSTM(128, 64, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Criar os datasets\n",
    "train_dataset = SequenceDataset(\n",
    "    path             = 'data/dataset/treino_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "valid_loader = SequenceDataset(\n",
    "    path             = 'data/dataset/validacao_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "\n",
    "print(f\"Total de amostras no conjunto de treino: {len(train_dataset)}\")\n",
    "print(f\"Total de amostras no conjunto de validação:  {len(valid_loader)}\")\n",
    "print(\"Train Dataset Shape:\", train_dataset.sequences.shape)\n",
    "print(\"valid Dataset Shape:\", valid_loader.sequences.shape)\n",
    "\n",
    "# Criar os DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader  = DataLoader(valid_loader,  batch_size=batch_size)\n",
    "\n",
    "print(f\"Total de batches no treino: {len(train_loader)}\")\n",
    "print(f\"Total de batches no validação:  {len(valid_loader)}\")\n",
    "\n",
    "# Instanciar o modelo\n",
    "n_features = train_dataset.sequences.shape[2]\n",
    "model = ModelHybridAttnSVM(\n",
    "    seq_len         = sequence_length,\n",
    "    n_features      = n_features,\n",
    "    lstm_hidden     = lstm_hidden,\n",
    "    lstm_layers     = lstm_layers,\n",
    "    num_classes     = num_classes\n",
    ").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 – Train Loss: 0.6918  Val Loss: 0.6898  Val Acc: 0.5199\n",
      "Epoch 2/100 – Train Loss: 0.4668  Val Loss: 0.1826  Val Acc: 0.9490\n",
      "Epoch 3/100 – Train Loss: 0.1730  Val Loss: 0.1332  Val Acc: 0.9614\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 4/100 – Train Loss: 0.1492  Val Loss: 0.1116  Val Acc: 0.9653\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 5/100 – Train Loss: 0.1363  Val Loss: 0.1409  Val Acc: 0.9604\n",
      "Epoch 6/100 – Train Loss: 0.1234  Val Loss: 0.1096  Val Acc: 0.9656\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 7/100 – Train Loss: 0.1154  Val Loss: 0.0954  Val Acc: 0.9716\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 8/100 – Train Loss: 0.1086  Val Loss: 0.0873  Val Acc: 0.9731\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 9/100 – Train Loss: 0.1093  Val Loss: 0.0925  Val Acc: 0.9719\n",
      "Epoch 10/100 – Train Loss: 0.1016  Val Loss: 0.0916  Val Acc: 0.9728\n",
      "Epoch 11/100 – Train Loss: 0.0988  Val Loss: 0.0884  Val Acc: 0.9734\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 12/100 – Train Loss: 0.0947  Val Loss: 0.1257  Val Acc: 0.9557\n",
      "Epoch 13/100 – Train Loss: 0.0958  Val Loss: 0.0796  Val Acc: 0.9765\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 14/100 – Train Loss: 0.0912  Val Loss: 0.0967  Val Acc: 0.9706\n",
      "Epoch 15/100 – Train Loss: 0.0947  Val Loss: 0.0866  Val Acc: 0.9745\n",
      "Epoch 16/100 – Train Loss: 0.0899  Val Loss: 0.0764  Val Acc: 0.9771\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 17/100 – Train Loss: 0.0890  Val Loss: 0.0748  Val Acc: 0.9775\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 18/100 – Train Loss: 0.0858  Val Loss: 0.1285  Val Acc: 0.9541\n",
      "Epoch 19/100 – Train Loss: 0.0839  Val Loss: 0.0841  Val Acc: 0.9738\n",
      "Epoch 20/100 – Train Loss: 0.0845  Val Loss: 0.0825  Val Acc: 0.9750\n",
      "Epoch 21/100 – Train Loss: 0.0794  Val Loss: 0.0798  Val Acc: 0.9763\n",
      "Epoch 22/100 – Train Loss: 0.0811  Val Loss: 0.0968  Val Acc: 0.9698\n",
      "Epoch 23/100 – Train Loss: 0.0798  Val Loss: 0.0855  Val Acc: 0.9740\n",
      "Epoch 24/100 – Train Loss: 0.0783  Val Loss: 0.0763  Val Acc: 0.9772\n",
      "Epoch 25/100 – Train Loss: 0.0757  Val Loss: 0.0761  Val Acc: 0.9780\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 26/100 – Train Loss: 0.0761  Val Loss: 0.0747  Val Acc: 0.9776\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 27/100 – Train Loss: 0.0749  Val Loss: 0.0743  Val Acc: 0.9780\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 28/100 – Train Loss: 0.0718  Val Loss: 0.0783  Val Acc: 0.9775\n",
      "Epoch 29/100 – Train Loss: 0.0710  Val Loss: 0.0800  Val Acc: 0.9772\n",
      "Epoch 30/100 – Train Loss: 0.0731  Val Loss: 0.0724  Val Acc: 0.9795\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 31/100 – Train Loss: 0.0702  Val Loss: 0.0740  Val Acc: 0.9794\n",
      "Epoch 32/100 – Train Loss: 0.0699  Val Loss: 0.0863  Val Acc: 0.9740\n",
      "Epoch 33/100 – Train Loss: 0.0693  Val Loss: 0.0689  Val Acc: 0.9795\n",
      "→ Checkpoint salvo: Hybrid_best_model.pth\n",
      "Epoch 34/100 – Train Loss: 0.0682  Val Loss: 0.0729  Val Acc: 0.9793\n",
      "Epoch 35/100 – Train Loss: 0.0683  Val Loss: 0.0712  Val Acc: 0.9780\n",
      "Epoch 36/100 – Train Loss: 0.0662  Val Loss: 0.0753  Val Acc: 0.9785\n",
      "Epoch 37/100 – Train Loss: 0.0652  Val Loss: 0.0989  Val Acc: 0.9702\n",
      "Epoch 38/100 – Train Loss: 0.0658  Val Loss: 0.0781  Val Acc: 0.9769\n",
      "Epoch 39/100 – Train Loss: 0.0625  Val Loss: 0.0746  Val Acc: 0.9783\n",
      "Epoch 40/100 – Train Loss: 0.0622  Val Loss: 0.0806  Val Acc: 0.9770\n",
      "Epoch 41/100 – Train Loss: 0.0615  Val Loss: 0.0800  Val Acc: 0.9758\n",
      "Epoch 42/100 – Train Loss: 0.0614  Val Loss: 0.0775  Val Acc: 0.9766\n",
      "Epoch 43/100 – Train Loss: 0.0617  Val Loss: 0.0736  Val Acc: 0.9794\n",
      "Epoch 44/100 – Train Loss: 0.0592  Val Loss: 0.0795  Val Acc: 0.9769\n",
      "Epoch 45/100 – Train Loss: 0.0589  Val Loss: 0.0780  Val Acc: 0.9780\n",
      "Epoch 46/100 – Train Loss: 0.0563  Val Loss: 0.0871  Val Acc: 0.9753\n",
      "Epoch 47/100 – Train Loss: 0.0552  Val Loss: 0.0788  Val Acc: 0.9782\n",
      "Epoch 48/100 – Train Loss: 0.0564  Val Loss: 0.0781  Val Acc: 0.9775\n",
      "Early stopping após 48 épocas sem melhora.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelHybridAttnSVM(\n",
       "  (conv1): Conv1d(9, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (relu): ReLU()\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (lstm1): LSTM(128, 64, num_layers=3, batch_first=True)\n",
       "  (lstm2): LSTM(64, 128, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (lstm3): LSTM(128, 64, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento\n",
    "model.train_model(\n",
    "    train_loader  = train_loader,\n",
    "    valid_loader  = valid_loader,\n",
    "    device        = device,\n",
    "    epochs        = epochs,\n",
    "    lr            = lr,\n",
    "    save_dir      = save_dir,\n",
    "    threshold     = threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(probability=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Treinar PCA + SVM sobre as features extraídas\n",
    "model.train_svm(\n",
    "    train_loader = valid_loader,\n",
    "    device       = device,\n",
    "    pca_path     = f\"{save_dir}/pca.joblib\",\n",
    "    svm_path     = f\"{save_dir}/hybrid_svm.joblib\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras de teste: 17099\n",
      "Test shape: torch.Size([17099, 50, 9])\n",
      "Checkpoint 'output/Hybrid/Hybrid_best_model.pth' carregado com sucesso!\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9779    0.9705    0.9742      8025\n",
      "           1     0.9741    0.9806    0.9773      9074\n",
      "\n",
      "    accuracy                         0.9758     17099\n",
      "   macro avg     0.9760    0.9755    0.9757     17099\n",
      "weighted avg     0.9759    0.9758    0.9758     17099\n",
      "\n",
      "Acurácia:  0.9758\n",
      "Precisão:  0.9741\n",
      "Recall:    0.9806\n",
      "F1-Score:  0.9773\n",
      "AUC:       0.9853\n"
     ]
    }
   ],
   "source": [
    "# Dataset e DataLoader para teste\n",
    "test_ds = SequenceDataset(\n",
    "    path             = 'data/dataset/teste_final_estratificado_random.csv',\n",
    "    sequence_length  = sequence_length,\n",
    "    column_to_remove = column_to_remove,\n",
    "    normalize        = True,\n",
    "    mode             = 'lstm'\n",
    ")\n",
    "print(f\"Total de amostras de teste: {len(test_ds)}\")\n",
    "print(\"Test shape:\", test_ds.sequences.shape)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Instanciar a classe Hybrid com os mesmos hiperparâmetros de treino\n",
    "n_features = test_ds.sequences.shape[2]  # dimensão de features por timestep\n",
    "model = ModelHybridAttnSVM(\n",
    "    seq_len        = sequence_length,\n",
    "    n_features     = n_features,\n",
    "    lstm_hidden    = lstm_hidden,\n",
    "    lstm_layers    = lstm_layers,\n",
    "    num_classes    = num_classes,\n",
    ").to(device)\n",
    "\n",
    "# Carregar checkpoint CNN-LSTM salvo \n",
    "checkpoint_path = 'output/Hybrid/Hybrid_best_model.pth'\n",
    "state = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "print(f\"Checkpoint '{checkpoint_path}' carregado com sucesso!\")\n",
    "\n",
    "# Avaliar pipeline completo (CNN→LSTM→PCA→SVM)\n",
    "model.evaluate(\n",
    "    loader    = test_loader,\n",
    "    device    = device,\n",
    "    pca_path  = 'output/Hybrid/pca.joblib',\n",
    "    svm_path  = 'output/Hybrid/hybrid_svm.joblib'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
